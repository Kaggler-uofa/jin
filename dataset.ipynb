{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import albumentations as Alb\n",
    "from skimage import transform\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \"\"\"\n",
    "    Configuration class for the blood vessel segmentation project.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ============== Model Configuration =============\n",
    "    MODEL_NAME = 'Unet'\n",
    "    BACKBONE = 'se_resnext50_32x4d'\n",
    "    IN_CHANNEL = 1  # Number of input channels (e.g., 1 for grayscale images)\n",
    "    OUT_CHANNEL = 1 # Number of output channels\n",
    "\n",
    "    # ============== Image Processing Settings =============\n",
    "    INPUT_IMAGE_SIZE = (1024, 1024)  # Size of the input images (height x width)\n",
    "    \n",
    "    # =============\n",
    "    # = Training and Validation Parameters =============\n",
    "    VALID_ID = 1  # ID for validation dataset or fold\n",
    "    BATCH_SIZE = 16  # Batch size for model training\n",
    "    THRESHOLD_PERCENTILE = 0.0014109  # Threshold for post-processing\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_EPOCHS = 50\n",
    "    NUM_WORKERS = 0 # Number of threds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 'kidney_2'\n",
    "\n",
    "image_path = os.path.join('..', 'data', 'train', data_set, 'images')\n",
    "label_path = os.path.join('..', 'data', 'train', data_set, 'labels')\n",
    "\n",
    "image_files = sorted([os.path.join(image_path, f) for f in os.listdir(image_path) if f.endswith('.tif')])\n",
    "label_files = sorted([os.path.join(label_path, f) for f in os.listdir(label_path) if f.endswith('.tif')])\n",
    "\n",
    "def display_image(image):\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        # If the input is a PyTorch tensor\n",
    "        if len(tensor.shape) == 4:\n",
    "            tensor = tensor.squeeze(0)\n",
    "\n",
    "        numpy_image = tensor.cpu().numpy()\n",
    "\n",
    "        if len(numpy_image.shape) == 3 and numpy_image.shape[0] == 1:\n",
    "            numpy_image = numpy_image.squeeze(0)\n",
    "\n",
    "        if len(numpy_image.shape) == 3:\n",
    "            numpy_image = numpy_image.transpose(1, 2, 0)\n",
    "\n",
    "    elif isinstance(tensor, np.ndarray):\n",
    "        # If the input is a NumPy array\n",
    "        numpy_image = tensor\n",
    "\n",
    "        if len(numpy_image.shape) == 3 and numpy_image.shape[0] == 1:\n",
    "            numpy_image = numpy_image.squeeze(0)\n",
    "    \n",
    "    plt.imshow(numpy_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_image = tifffile.imread(image_files[981])\n",
    "first_label = tifffile.imread(label_files[981])\n",
    "\n",
    "is_image = isinstance(first_image, np.ndarray)\n",
    "is_mask = isinstance(first_label, np.ndarray)\n",
    "print(is_image, is_mask)\n",
    "\n",
    "# Convert tensor floats32\n",
    "first_image_tensor = torch.from_numpy(first_image.astype(np.float32))\n",
    "first_label_tensor = torch.from_numpy(first_label.astype(np.float32))\n",
    "\n",
    "display_image(first_image_tensor)\n",
    "display_image(first_label_tensor)\n",
    "\n",
    "is_image_tensor = isinstance(first_image_tensor, torch.Tensor)\n",
    "is_mask_tensor = isinstance(first_label_tensor, torch.Tensor)\n",
    "print(is_image_tensor, is_mask_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augement_image(image, mask):\n",
    "\n",
    "    image_dense = torch.from_numpy(image.astype(np.float32))\n",
    "    mask_dense = torch.from_numpy(mask.astype(np.float32))\n",
    "\n",
    "    if len(image_dense.shape) == 2:\n",
    "        image_dense = image_dense.unsqueeze(0)\n",
    "\n",
    "    image_np = image_dense.permute(1, 2, 0).numpy()\n",
    "    mask_np = mask_dense.numpy()\n",
    "\n",
    "    image_list = [None, None, None, None]\n",
    "    mask_list = [None, None, None, None]\n",
    "    \n",
    "    transform_rotate_90 = Alb.Compose([\n",
    "        Alb.Rotate(limit=90, p=0.5)\n",
    "    ])\n",
    "\n",
    "    # Original image\n",
    "    image_list[0] = image_np\n",
    "    mask_list[0] = mask_np\n",
    "\n",
    "    # Original image with 90-degree rotation\n",
    "    augmented_rotate_90 = transform_rotate_90(image=image_np, mask=mask_np)\n",
    "    image_list[1], mask_list[1] = augmented_rotate_90['image'], augmented_rotate_90['mask']\n",
    "\n",
    "    # Original image with 180-degree rotation\n",
    "    augmented_rotate_180 = transform_rotate_90(image=image_list[1], mask=mask_list[1])   \n",
    "    image_list[2], mask_list[2] = augmented_rotate_180['image'], augmented_rotate_180['mask']\n",
    "\n",
    "    # Original image with 270-degree rotation\n",
    "    augmented_rotate_270 = transform_rotate_90(image=image_list[2], mask=mask_list[2])\n",
    "    image_list[3], mask_list[3] = augmented_rotate_270['image'], augmented_rotate_270['mask']\n",
    "\n",
    "    # Making the mask dimentions 3\n",
    "    for i in range(4):\n",
    "        if mask_list[i].ndim == 2:\n",
    "            mask_list[i] = mask_list[i][..., np.newaxis]\n",
    "\n",
    "    augmented_data_zip = list(zip(*[image_list, mask_list]))\n",
    "\n",
    "    return augmented_data_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image and label\n",
    "first_image = tifffile.imread(image_files[981])\n",
    "first_label = tifffile.imread(label_files[981])\n",
    "\n",
    "# Augment the image and label\n",
    "# augmented_image, augmented_mask = Augement_image(first_image, first_label)\n",
    "augmented_zip = Augement_image(first_image, first_label)\n",
    "\n",
    "# Show the augmented image\n",
    "# display_image(augmented_image)\n",
    "# display_image(augmented_mask)\n",
    "\n",
    "# is_image_tensor = isinstance(augmented_image, np.ndarray)\n",
    "# is_mask_tensor = isinstance(augmented_mask, np.ndarray)\n",
    "# print(is_image_tensor, is_mask_tensor)\n",
    "# print(augmented_zip)\n",
    "# display_image(augmented_zip[-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=augmented_zip,   # using subset\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "for batch_idx, (batch_images, batch_masks) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(f\"  Image shapes: {[img.shape for img in batch_images]}\")\n",
    "    print(f\"  Mask shapes: {[mask.shape for mask in batch_masks]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
