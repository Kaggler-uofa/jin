{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import albumentations as Alb\n",
    "from skimage import transform\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ============= MODEL CFG ================\n",
    "    model_name = \"Unet\"\n",
    "    backbone = 'se_resnext50_32x4d'\n",
    "\n",
    "    # ============= Image Processing Setup ================\n",
    "    image_size = 1024\n",
    "    input_size= 1024\n",
    "    tile_size = image_size\n",
    "    stride = tile_size // 4\n",
    "    drop_edge_pixel = 0\n",
    "\n",
    "    target_size = 1\n",
    "\n",
    "    # ==========================================================\n",
    "    valid_id = 1\n",
    "    batch_size = 16\n",
    "\n",
    "    # ============ Model PATH =================\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 'kidney_2'\n",
    "\n",
    "image_path = os.path.join('..', 'data', 'train', data_set, 'images')\n",
    "label_path = os.path.join('..', 'data', 'train', data_set, 'labels')\n",
    "\n",
    "image_files = sorted([os.path.join(image_path, f) for f in os.listdir(image_path) if f.endswith('.tif')])\n",
    "label_files = sorted([os.path.join(label_path, f) for f in os.listdir(label_path) if f.endswith('.tif')])\n",
    "\n",
    "def display_image(tensor):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        # If the input is a PyTorch tensor\n",
    "        if len(tensor.shape) == 4:\n",
    "            tensor = tensor.squeeze(0)\n",
    "\n",
    "        numpy_image = tensor.cpu().numpy()\n",
    "\n",
    "        if len(numpy_image.shape) == 3 and numpy_image.shape[0] == 1:\n",
    "            numpy_image = numpy_image.squeeze(0)\n",
    "\n",
    "        if len(numpy_image.shape) == 3:\n",
    "            numpy_image = numpy_image.transpose(1, 2, 0)\n",
    "\n",
    "    elif isinstance(tensor, np.ndarray):\n",
    "        # If the input is a NumPy array\n",
    "        numpy_image = tensor\n",
    "\n",
    "        if len(numpy_image.shape) == 3 and numpy_image.shape[0] == 1:\n",
    "            numpy_image = numpy_image.squeeze(0)\n",
    "    \n",
    "    plt.imshow(numpy_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_image = tifffile.imread(image_files[981])\n",
    "first_label = tifffile.imread(label_files[981])\n",
    "\n",
    "is_image = isinstance(first_image, np.ndarray)\n",
    "is_mask = isinstance(first_label, np.ndarray)\n",
    "print(is_image, is_mask)\n",
    "\n",
    "# Convert tensor floats32\n",
    "first_image_tensor = torch.from_numpy(first_image.astype(np.float32))\n",
    "first_label_tensor = torch.from_numpy(first_label.astype(np.float32))\n",
    "\n",
    "display_image(first_image_tensor)\n",
    "display_image(first_label_tensor)\n",
    "\n",
    "is_image_tensor = isinstance(first_image_tensor, torch.Tensor)\n",
    "is_mask_tensor = isinstance(first_label_tensor, torch.Tensor)\n",
    "print(is_image_tensor, is_mask_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augement_image(image, mask):\n",
    "\n",
    "    image_dense = torch.from_numpy(image.astype(np.float32))\n",
    "    mask_dense = torch.from_numpy(mask.astype(np.float32))\n",
    "\n",
    "    if len(image_dense.shape) == 2:\n",
    "        image_dense = image_dense.unsqueeze(0)\n",
    "\n",
    "    image_np = image_dense.permute(1, 2, 0).numpy()\n",
    "    mask_np = mask_dense.numpy()\n",
    "\n",
    "    image_list = [None, None, None, None]\n",
    "    mask_list = [None, None, None, None]\n",
    "    \n",
    "    transform_rotate_90 = Alb.Compose([\n",
    "        Alb.Rotate(limit=90, p=0.5)\n",
    "    ])\n",
    "\n",
    "    # Original image\n",
    "    image_list[0] = image_np\n",
    "    mask_list[0] = mask_np\n",
    "\n",
    "    # Original image with 90-degree rotation\n",
    "    augmented_rotate_90 = transform_rotate_90(image=image_np, mask=mask_np)\n",
    "    image_list[1], mask_list[1] = augmented_rotate_90['image'], augmented_rotate_90['mask']\n",
    "\n",
    "    # Original image with 180-degree rotation\n",
    "    augmented_rotate_180 = transform_rotate_90(image=image_list[1], mask=mask_list[1])   \n",
    "    image_list[2], mask_list[2] = augmented_rotate_180['image'], augmented_rotate_180['mask']\n",
    "\n",
    "    # Original image with 270-degree rotation\n",
    "    augmented_rotate_270 = transform_rotate_90(image=image_list[2], mask=mask_list[2])\n",
    "    image_list[3], mask_list[3] = augmented_rotate_270['image'], augmented_rotate_270['mask']\n",
    "\n",
    "    # Making the mask dimentions 3\n",
    "    for i in range(4):\n",
    "        if mask_list[i].ndim == 2:\n",
    "            mask_list[i] = mask_list[i][..., np.newaxis]\n",
    "\n",
    "    augmented_data_zip = list(zip(*[image_list, mask_list]))\n",
    "\n",
    "    return augmented_data_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example image and label\n",
    "first_image = tifffile.imread(image_files[981])\n",
    "first_label = tifffile.imread(label_files[981])\n",
    "\n",
    "# Augment the image and label\n",
    "# augmented_image, augmented_mask = Augement_image(first_image, first_label)\n",
    "augmented_zip = Augement_image(first_image, first_label)\n",
    "\n",
    "# Show the augmented image\n",
    "# display_image(augmented_image)\n",
    "# display_image(augmented_mask)\n",
    "\n",
    "# is_image_tensor = isinstance(augmented_image, np.ndarray)\n",
    "# is_mask_tensor = isinstance(augmented_mask, np.ndarray)\n",
    "# print(is_image_tensor, is_mask_tensor)\n",
    "# print(augmented_zip)\n",
    "# display_image(augmented_zip[-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  Image shapes: [torch.Size([1041, 1511, 1]), torch.Size([1041, 1511, 1]), torch.Size([1041, 1511, 1]), torch.Size([1041, 1511, 1])]\n",
      "  Mask shapes: [torch.Size([1041, 1511, 1]), torch.Size([1041, 1511, 1]), torch.Size([1041, 1511, 1]), torch.Size([1041, 1511, 1])]\n"
     ]
    }
   ],
   "source": [
    "# Define loaders\n",
    "train_loader = DataLoader(\n",
    "    dataset=augmented_zip,   # using subset\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "for batch_idx, (batch_images, batch_masks) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx}:\")\n",
    "    print(f\"  Image shapes: {[img.shape for img in batch_images]}\")\n",
    "    print(f\"  Mask shapes: {[mask.shape for mask in batch_masks]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
